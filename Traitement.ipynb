{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0483924a",
   "metadata": {},
   "source": [
    "1. Load your CSVs;\n",
    "\n",
    "(dans le cas suivant, seloger_v10_20251211_155543.csv,seloger_v10_20251211_164416.csv)\n",
    "\n",
    "Ces datasets ont Ã©tÃ© crÃ©es par code_scraper_v10. Ce dernier a Ã©tÃ© lancÃ© 2 fois en vu d'augmenter la qualitÃ© du dataframe final car ces CSVs ont beaucoup de valeurs N/A, mais rarement au meme endroit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8c67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"Web-Scraping-Immobilier/seloger_v10_20251211_155543.csv\")\n",
    "df2 = pd.read_csv(\"Web-Scraping-Immobilier/seloger_v10_20251211_164416.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf9d24",
   "metadata": {},
   "source": [
    "2. Standardize the data\n",
    "\n",
    "This handles different spellings of N/A, blank strings, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae41917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NORMALIZE ---\n",
    "for df in (df1, df2):\n",
    "    df.replace([\"N/A\", \"NA\", \"\", \" \", None], pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c885fc",
   "metadata": {},
   "source": [
    "3. We remove exact duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567bade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates\n",
    "df1 = df1.drop_duplicates()\n",
    "df2 = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54d5a4",
   "metadata": {},
   "source": [
    "Categorise both dataframes by whether they have a URL in their URL column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d01383",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split by URL availability\n",
    "df1_with = df1[df1[\"URL\"].notna()]\n",
    "df1_no   = df1[df1[\"URL\"].isna()]\n",
    "df2_with = df2[df2[\"URL\"].notna()]\n",
    "df2_no   = df2[df2[\"URL\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f21c8",
   "metadata": {},
   "source": [
    "Merge rows that HAVE URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9c9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_with_url = pd.merge(\n",
    "    df1_with, df2_with,\n",
    "    on=\"URL\",\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_df1\", \"_df2\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96764060",
   "metadata": {},
   "source": [
    "Coalesce columns (choose non-null values)\n",
    "\n",
    "This avoids duplicate columns and fills gaps using both datasets.\n",
    "\n",
    "We will get a clean, merged-deduped, coalesced dataset for all entries that have a URL, for both datasets where their rows have a valid URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53da2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to coalesce (everything except URL)\n",
    "cols = [c for c in df1.columns if c != \"URL\"]\n",
    "\n",
    "def coalesce(row, col):\n",
    "    v1 = row.get(f\"{col}_df1\", pd.NA)\n",
    "    v2 = row.get(f\"{col}_df2\", pd.NA)\n",
    "    return v1 if pd.notna(v1) else v2\n",
    "\n",
    "for col in cols:\n",
    "    merged_with_url[col] = merged_with_url.apply(lambda row: coalesce(row, col), axis=1)\n",
    "\n",
    "# Keep only final clean columns\n",
    "merged_with_url_clean = merged_with_url[[\"URL\"] + cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa52b78",
   "metadata": {},
   "source": [
    "3. Fuzzy merge for rows WITHOUT URLs, where at least one of the two dataframe rows don't have a URL\n",
    "\n",
    "(Merge if â‰¥3 fields match, when fields aren't N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2857ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_cols = [\n",
    "    \"Type\", \"Price\", \"Price_Per_M2\", \"Surface_m2\",\n",
    "    \"Rooms\", \"Bedrooms\", \"Delivery_Date\", \"Address\",\n",
    "    \"City\", \"PostalCode\", \"Department\", \"Program_Name\"\n",
    "]\n",
    "\n",
    "def find_matches(row, df_other, threshold=3):\n",
    "    comparisons = df_other[match_cols].eq(row[match_cols], axis=1)\n",
    "    score = comparisons.sum(axis=1)\n",
    "    return df_other[score >= threshold]\n",
    "\n",
    "merged_no_url_rows = []\n",
    "\n",
    "for _, row in df1_no.iterrows():\n",
    "    matches = find_matches(row, df2_no, threshold=3)\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        merged_no_url_rows.append(row.to_dict())\n",
    "    else:\n",
    "        for _, match in matches.iterrows():\n",
    "            combined = {}\n",
    "            for col in df1.columns:\n",
    "                # coalesce the two rows\n",
    "                v1 = row[col]\n",
    "                v2 = match[col]\n",
    "                combined[col] = v1 if pd.notna(v1) else v2\n",
    "            merged_no_url_rows.append(combined)\n",
    "\n",
    "merged_no_url = pd.DataFrame(merged_no_url_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611ccec",
   "metadata": {},
   "source": [
    "Combine URL and no-URL merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd05f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([merged_with_url_clean, merged_no_url], ignore_index=True)\n",
    "\n",
    "# Final deduplication\n",
    "final = final.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e46dd",
   "metadata": {},
   "source": [
    "5. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8356dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved as: merged_clean_output.csv (UTF-8 BOM, Excel compatible)\n"
     ]
    }
   ],
   "source": [
    "# Save merged CSV with UTF-8 BOM for Excel compatibility\n",
    "output_filename = \"merged_clean_output.csv\"\n",
    "final.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Merged CSV saved as: {output_filename} (UTF-8 BOM, Excel compatible)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda405c",
   "metadata": {},
   "source": [
    "6. Check final csv for duplicates/ remaining N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43c67b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Total rows with problematic missing data: 614\n",
      "\n",
      "                                                     URL         Type Price  \\\n",
      "1      https://www.bellesdemeures.com/205139579/detai...       Maison   NaN   \n",
      "183    https://www.bellesdemeures.com/249173485/detai...  Appartement   NaN   \n",
      "186    https://www.bellesdemeures.com/249202237/detai...  Appartement   NaN   \n",
      "236    https://www.bellesdemeures.com/250118407/detai...  Appartement   NaN   \n",
      "239    https://www.bellesdemeures.com/250131653/detai...  Appartement   NaN   \n",
      "...                                                  ...          ...   ...   \n",
      "11327                                                NaN          NaN   NaN   \n",
      "11328                                                NaN          NaN   NaN   \n",
      "11329                                                NaN          NaN   NaN   \n",
      "11330                                                NaN          NaN   NaN   \n",
      "11331                                                NaN          NaN   NaN   \n",
      "\n",
      "      Price_Per_M2 Surface_m2 Rooms Bedrooms Address City  PostalCode  \\\n",
      "1              NaN      86 mÂ²     4        2     NaN  NaN     75011.0   \n",
      "183            NaN      40 mÂ²     2        1     NaN  NaN     75006.0   \n",
      "186            NaN   147,8 mÂ²     6        4     NaN  NaN     75016.0   \n",
      "236            NaN      78 mÂ²     3        2     NaN  NaN     75001.0   \n",
      "239            NaN      98 mÂ²     3        2     NaN  NaN     75010.0   \n",
      "...            ...        ...   ...      ...     ...  ...         ...   \n",
      "11327          NaN        NaN   NaN      NaN     NaN  NaN         NaN   \n",
      "11328          NaN        NaN   NaN      NaN     NaN  NaN         NaN   \n",
      "11329          NaN        NaN   NaN      NaN     NaN  NaN         NaN   \n",
      "11330          NaN        NaN   NaN      NaN     NaN  NaN         NaN   \n",
      "11331          NaN        NaN   NaN      NaN     NaN  NaN         NaN   \n",
      "\n",
      "       Department Program_Name  \n",
      "1            75.0          NaN  \n",
      "183          75.0          NaN  \n",
      "186          75.0          NaN  \n",
      "236          75.0          NaN  \n",
      "239          75.0          NaN  \n",
      "...           ...          ...  \n",
      "11327         NaN          NaN  \n",
      "11328         NaN          NaN  \n",
      "11329         NaN          NaN  \n",
      "11330         NaN          NaN  \n",
      "11331         NaN          NaN  \n",
      "\n",
      "[614 rows x 12 columns]\n",
      "\n",
      "ðŸ”¹ Duplicate URLs (total 22):\n",
      "        URL  Page_Number Type Price Price_Per_M2 Surface_m2 Rooms Bedrooms  \\\n",
      "11310  NaN         41.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11311  NaN         54.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11312  NaN         68.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11313  NaN         58.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11314  NaN         76.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11315  NaN         94.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11316  NaN        154.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11317  NaN        171.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11318  NaN        186.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11319  NaN        192.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11320  NaN        207.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11321  NaN        213.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11322  NaN        212.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11323  NaN        223.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11324  NaN        220.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11325  NaN        218.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11326  NaN        203.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11327  NaN        233.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11328  NaN        232.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11329  NaN        224.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11330  NaN        268.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11331  NaN        306.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "\n",
      "      Delivery_Date Address City  PostalCode  Department Program_Name  \\\n",
      "11310           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11311           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11312           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11313           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11314           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11315           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11316           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11317           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11318           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11319           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11320           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11321           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11322           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11323           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11324           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11325           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11326           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11327           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11328           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11329           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11330           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11331           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "\n",
      "       Confidence_Score  Raw_Card_Text  \n",
      "11310               3.0            NaN  \n",
      "11311               3.0            NaN  \n",
      "11312               3.0            NaN  \n",
      "11313               3.0            NaN  \n",
      "11314               3.0            NaN  \n",
      "11315               3.0            NaN  \n",
      "11316               3.0            NaN  \n",
      "11317               3.0            NaN  \n",
      "11318               3.0            NaN  \n",
      "11319               3.0            NaN  \n",
      "11320               3.0            NaN  \n",
      "11321               3.0            NaN  \n",
      "11322               3.0            NaN  \n",
      "11323               3.0            NaN  \n",
      "11324               3.0            NaN  \n",
      "11325               3.0            NaN  \n",
      "11326               3.0            NaN  \n",
      "11327               3.0            NaN  \n",
      "11328               3.0            NaN  \n",
      "11329               3.0            NaN  \n",
      "11330               3.0            NaN  \n",
      "11331               3.0            NaN  \n",
      "\n",
      "ðŸ”¹ Exact duplicate rows (critical columns, total 22):\n",
      "        URL  Page_Number Type Price Price_Per_M2 Surface_m2 Rooms Bedrooms  \\\n",
      "11310  NaN         41.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11311  NaN         54.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11312  NaN         68.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11313  NaN         58.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11314  NaN         76.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11315  NaN         94.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11316  NaN        154.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11317  NaN        171.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11318  NaN        186.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11319  NaN        192.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11320  NaN        207.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11321  NaN        213.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11322  NaN        212.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11323  NaN        223.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11324  NaN        220.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11325  NaN        218.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11326  NaN        203.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11327  NaN        233.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11328  NaN        232.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11329  NaN        224.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11330  NaN        268.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "11331  NaN        306.0  NaN   NaN          NaN        NaN   NaN      NaN   \n",
      "\n",
      "      Delivery_Date Address City  PostalCode  Department Program_Name  \\\n",
      "11310           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11311           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11312           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11313           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11314           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11315           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11316           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11317           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11318           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11319           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11320           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11321           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11322           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11323           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11324           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11325           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11326           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11327           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11328           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11329           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11330           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "11331           NaN     NaN  NaN         NaN         NaN          NaN   \n",
      "\n",
      "       Confidence_Score  Raw_Card_Text  \n",
      "11310               3.0            NaN  \n",
      "11311               3.0            NaN  \n",
      "11312               3.0            NaN  \n",
      "11313               3.0            NaN  \n",
      "11314               3.0            NaN  \n",
      "11315               3.0            NaN  \n",
      "11316               3.0            NaN  \n",
      "11317               3.0            NaN  \n",
      "11318               3.0            NaN  \n",
      "11319               3.0            NaN  \n",
      "11320               3.0            NaN  \n",
      "11321               3.0            NaN  \n",
      "11322               3.0            NaN  \n",
      "11323               3.0            NaN  \n",
      "11324               3.0            NaN  \n",
      "11325               3.0            NaN  \n",
      "11326               3.0            NaN  \n",
      "11327               3.0            NaN  \n",
      "11328               3.0            NaN  \n",
      "11329               3.0            NaN  \n",
      "11330               3.0            NaN  \n",
      "11331               3.0            NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Load merged cleaned dataset ---\n",
    "final = pd.read_csv(\"merged_clean_output.csv\")\n",
    "\n",
    "# --- Columns to check ---\n",
    "critical_cols = [\"URL\",\"Type\",\"Price\",\"Price_Per_M2\",\"Surface_m2\",\n",
    "                 \"Rooms\",\"Bedrooms\",\"Address\",\"City\",\"PostalCode\",\n",
    "                 \"Department\",\"Program_Name\"]\n",
    "\n",
    "# --- Filter to only critical columns ---\n",
    "df_crit = final[critical_cols].copy()\n",
    "\n",
    "# --- Identify rows with problematic missing data ---\n",
    "def is_problematic(row):\n",
    "    # Check for NAs in critical columns\n",
    "    crit_na = row.isna()\n",
    "    \n",
    "    # If Price or Price_Per_M2 has data AND City/Address/PostalCode has data â†’ not a problem\n",
    "    price_ok = pd.notna(row[\"Price\"]) or pd.notna(row[\"Price_Per_M2\"])\n",
    "    location_ok = pd.notna(row[\"City\"]) or pd.notna(row[\"Address\"]) or pd.notna(row[\"PostalCode\"])\n",
    "    \n",
    "    # Row is problematic if there are any NAs in critical columns AND not enough data\n",
    "    if price_ok and location_ok:\n",
    "        return False\n",
    "    # Else, check if any critical field is missing\n",
    "    return crit_na.any()\n",
    "\n",
    "rows_problematic = df_crit[df_crit.apply(is_problematic, axis=1)]\n",
    "\n",
    "print(f\"ðŸ”¹ Total rows with problematic missing data: {len(rows_problematic)}\\n\")\n",
    "print(rows_problematic)\n",
    "\n",
    "# --- Check for duplicates (URL or full critical columns) ---\n",
    "duplicate_urls = final[final.duplicated(subset=[\"URL\"], keep=False)]\n",
    "print(f\"\\nðŸ”¹ Duplicate URLs (total {len(duplicate_urls)}):\\n\", duplicate_urls)\n",
    "\n",
    "duplicate_rows = final[final.duplicated(subset=critical_cols, keep=False)]\n",
    "print(f\"\\nðŸ”¹ Exact duplicate rows (critical columns, total {len(duplicate_rows)}):\\n\", duplicate_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8b1d1",
   "metadata": {},
   "source": [
    "6.B : Optional: save report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_file = \"merged_clean_report.xlsx\"\n",
    "with pd.ExcelWriter(report_file) as writer:\n",
    "    rows_problematic.to_excel(writer, sheet_name=\"Problematic_Rows\", index=False)\n",
    "    duplicate_urls.to_excel(writer, sheet_name=\"Duplicate_URLs\", index=False)\n",
    "    duplicate_rows.to_excel(writer, sheet_name=\"Duplicate_Rows\", index=False)\n",
    "\n",
    "print(f\"\\nâœ… Report saved as '{report_file}'. Review problematic rows and duplicates there.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
